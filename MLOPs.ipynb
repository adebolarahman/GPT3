{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ad726d3-7c22-4608-90d0-4e8d2817a1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import openai\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import tiktoken\n",
    "import time\n",
    "from google.cloud import storage\n",
    "import csv\n",
    "import json\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "time.sleep(1.0)\n",
    "COMPLETIONS_MODEL = \"text-davinci-003\"\n",
    "EMBEDDING_MODEL = \"text-embedding-ada-002\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "24ba96ab-2e2d-4997-838a-23fc22801bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!gcsfuse generative-ai /home/jupyter/bucket"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f9f66e-91c7-4b33-a649-dcab87c7a662",
   "metadata": {},
   "source": [
    "Files save in Buckets mlops_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22e6029e-8776-4356-8e3e-5a3775e7096c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "client = storage.Client()\n",
    "BUCKET_NAME = 'mlops_documents'\n",
    "bucket = client.get_bucket(BUCKET_NAME)\n",
    "elements = bucket.list_blobs()\n",
    "files=[a.name for a in elements]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2dcacbc-98f2-4ec3-b5a5-b7aca2884713",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['df1.csv', 'df_clean.csv', 'df_clean_10_documents.csv', 'embedding.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f17f28ad-d5ec-4ccf-aebc-be00040494ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade google-cloud-storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168cbc42-bbfb-4637-abd0-41bc0e1a9129",
   "metadata": {},
   "source": [
    "Import the file into Notebook from mlops_documents bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc1de52e-0c56-48e2-8e96-5190d4751422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>text content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AllInOnAI PREVIEW_10.txt</td>\n",
       "      <td>What Does It Mean to Be AI Fueled?Some— but not nearly enough—of the most successful and most technological organizations in the world have declared their intention to be all-in on artificial intelligence, or “AI first” or “AI fueled.” Google described it as “a world that is AI- first, where computing becomes universally available—be it at home, at work, in the car, or on the go— and interacting with all of  these surfaces becomes much more natural and intuitive, and above all, more intelligent.” Companies seeking to be powered by AI in other industries share the goal of intuitive technology and pervasive intelligence but are applying those objectives to their own industries, such as financial services, manufacturing, or health care.The AI- fueled organizations in our analysis comprise less than 1 percent of large companies. It wasn’t easy to find enough to write about in this book, but we  were able to discover about thirty. We expect, however, that many more organizations  will move in this direction. And why  wouldn’t they? The companies we describe inthis book perform well. They have effective business models, make good decisions, have close relationships with customers, offer desir-able products and services, and charge profitable prices.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   filename  \\\n",
       "0  AllInOnAI PREVIEW_10.txt   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      text content  \n",
       "0  What Does It Mean to Be AI Fueled?Some— but not nearly enough—of the most successful and most technological organizations in the world have declared their intention to be all-in on artificial intelligence, or “AI first” or “AI fueled.” Google described it as “a world that is AI- first, where computing becomes universally available—be it at home, at work, in the car, or on the go— and interacting with all of  these surfaces becomes much more natural and intuitive, and above all, more intelligent.” Companies seeking to be powered by AI in other industries share the goal of intuitive technology and pervasive intelligence but are applying those objectives to their own industries, such as financial services, manufacturing, or health care.The AI- fueled organizations in our analysis comprise less than 1 percent of large companies. It wasn’t easy to find enough to write about in this book, but we  were able to discover about thirty. We expect, however, that many more organizations  will move in this direction. And why  wouldn’t they? The companies we describe inthis book perform well. They have effective business models, make good decisions, have close relationships with customers, offer desir-able products and services, and charge profitable prices.  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = \"mlops_documents\"\n",
    "\n",
    "storage_client = storage.Client()\n",
    "bucket = storage_client.get_bucket(bucket_name)\n",
    "\n",
    "# When you have your files in a subfolder of the bucket.\n",
    "my_prefix = \"csv/\" # the name of the subfolder\n",
    "blobs = bucket.list_blobs(prefix = my_prefix, delimiter = '/')\n",
    "\n",
    "for blob in blobs:\n",
    "    if(blob.name != my_prefix): # ignoring the subfolder itself \n",
    "        file_name = blob.name.replace(my_prefix, \"\")\n",
    "        blob.download_to_filename(file_name) # download the file to the machine\n",
    "        df = pd.read_csv(file_name) # load the data\n",
    "        print(df)\n",
    "\n",
    "# When you have your files on the first level of your bucket\n",
    "\n",
    "blobs = bucket.list_blobs()\n",
    "\n",
    "for blob in blobs:\n",
    "    file_name = blob.name\n",
    "    blob.download_to_filename(file_name)\n",
    "    data = pd.read_csv('df_clean_10_documents.csv') # load the data\n",
    "data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "beb8a951-ead3-45aa-918b-b452963bbcbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(260, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b9b01ab-8e97-4f4d-9c38-e49e2fea4364",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['text content'] = data['text content'].replace(np.nan, '')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaef726-44b6-43c2-80ce-c4f8925e9a13",
   "metadata": {},
   "source": [
    "Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19138bf2-9388-48dc-b00a-cf70a832f311",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jupyter/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk \n",
    "nltk.download('punkt')\n",
    "data['tokenized_sents'] = data.apply(lambda row: nltk.word_tokenize(row['text content']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a6c85b6-2b1e-4e91-b8b5-24d793d42486",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['len_tokens'] = data['tokenized_sents'].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "69c78c57-3f68-4929-aba4-03fdee8ec405",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data['tokenized_sents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "77df0b21-c09b-43dd-9f63-683f9def55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['tokenized_text'] = [' '.join(map(str, l)) for l in data['tokenized_sents']]\n",
    "#data['tokenized_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80909c14-550e-477a-9c0d-5faec9fe32e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['len_tokens']>40]\n",
    "#data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "408b9cdf-1eed-40f6-ac13-a80bd23fecfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Marcelo Chierighini of Brazil won the gold medal in the men's high jump at the 2020 Summer Olympics.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reference https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb\n",
    "prompt = \"Who won the 2020 Summer Olympics men's high jump?\"\n",
    "openai.api_key = \"yourkey\"\n",
    "openai.Completion.create(\n",
    "    prompt=prompt,\n",
    "    temperature=0,\n",
    "    max_tokens=300,\n",
    "    model=COMPLETIONS_MODEL\n",
    ")[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cb57c6e-04a8-4c57-b5cf-009802db0c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "#reference https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb\n",
    "def get_embedding(text: str, model: str=EMBEDDING_MODEL) -> list:\n",
    "    time.sleep(1.0)\n",
    "    result = openai.Embedding.create(\n",
    "      model=model,\n",
    "      input=text\n",
    "    )\n",
    "    return result[\"data\"][0][\"embedding\"]\n",
    "    \n",
    "def compute_doc_embeddings(df: pd.DataFrame) -> list:\n",
    "    time.sleep(1.0)\n",
    "    \"\"\"\n",
    "    Create an embedding for each row in the dataframe using the OpenAI Embeddings API.\n",
    "    \n",
    "    Return a dictionary that maps between each embedding vector and the index of the row that it corresponds to.\n",
    "    \"\"\"\n",
    "    return {\n",
    "        idx: get_embedding(r.content) for idx, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0018dde0-888c-4043-8056-93a602322c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings(fname: str) -> dict:\n",
    "    time.sleep(1.0)\n",
    "    \"\"\"\n",
    "    Read the document embeddings and their keys from a CSV.\n",
    "    \n",
    "    fname is the path to a CSV with exactly these named columns: \n",
    "        \"title\", \"heading\", \"0\", \"1\", ... up to the length of the embedding vectors.\n",
    "    \"\"\"\n",
    "    \n",
    "    df = pd.read_csv(fname, header=0)\n",
    "    max_dim = max([int(c) for c in df.columns if c != \"title\" and c != \"heading\"])\n",
    "    return {\n",
    "           (r.title, r.heading): [r[str(i)] for i in range(max_dim + 1)] for _, r in df.iterrows()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "73c1df37-90df-46bc-9c77-10d8c70f8444",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data=data[['filename', 'text content', 'len_tokens','tokenized_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c88e5c43-980d-4fd0-88e8-2959183aacda",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.rename(columns={'filename':'title','text content':'heading','tokenized_text':'content','len_tokens':'tokens'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2b9276f5-4006-4724-afed-1e2662408ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.set_index([\"title\", \"heading\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a6b6780-2f36-4e78-8880-1f38ce1cc0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['tokenized_sents'], axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d6179e14-330c-4113-9b33-0107b0635a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tokens', 'content'], dtype='object')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b1b608ad-4c09-484a-a290-27f7dcafb002",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[['content','tokens']]\n",
    "#data.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7f09d79f-687e-4b5c-a6f1-aa8f03b38608",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6aeb99f3-7de6-4dce-9661-ef4b46c49b3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(254, 2)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24e80f3e-14cc-4593-8d05-9844f13d8658",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.to_csv('/data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6913773c-b804-437d-ac89-f0285d0f26de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#time.sleep(1.0)\n",
    "#document_embeddings = compute_doc_embeddings(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "57d60b09-5828-40da-b26f-d218a49fd22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "from google.cloud import storage\n",
    "\n",
    "# Create a storage client\n",
    "storage_client = storage.Client()\n",
    "\n",
    "# Get the bucket\n",
    "bucket = storage_client.get_bucket(\"mlops_documents\")\n",
    "\n",
    "# Get the blob\n",
    "blob = bucket.get_blob(\"embedding.txt\")\n",
    "\n",
    "# Read the contents of the blob\n",
    "blob_string = blob.download_as_string()\n",
    "\n",
    "# Create a file-like object\n",
    "blob_file = io.BytesIO(blob_string)\n",
    "\n",
    "# Read the file\n",
    "file_contents = blob_file.read()\n",
    "#file_contents\n",
    "# Print the contents of the file\n",
    "#print(file_contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df505c0c-297a-4eec-95ef-149b32d2157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "document_embeddings = ast.literal_eval(file_contents.decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c714fdf7-3b6f-42f4-bd5b-a7ad799fba07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load_embeddings('my_dict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6c237380-c526-4efc-a184-403a12dcce3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AllInOnAI PREVIEW_10.txt', 'What Does It Mean to Be AI Fueled?Some— but not nearly enough—of the most successful and most technological organizations in the world have declared their intention to be all-in on artificial intelligence, or “AI first” or “AI fueled.” Google described it as “a world that is AI- first, where computing becomes universally available—be it at home, at work, in the car, or on the go— and interacting with all of  these surfaces becomes much more natural and intuitive, and above all, more intelligent.” Companies seeking to be powered by AI in other industries share the goal of intuitive technology and pervasive intelligence but are applying those objectives to their own industries, such as financial services, manufacturing, or health care.The AI- fueled organizations in our analysis comprise less than 1\\xa0percent of large companies. It wasn’t easy to find enough to write about in this book, but we  were able to discover about thirty. We expect, however, that many more organizations  will move in this direction. And why  wouldn’t they? The companies we describe inthis book perform well. They have effective business models, make good decisions, have close relationships with customers, offer desir-able products and services, and charge profitable prices.') : [-0.009173513390123844, -0.018575021997094154, -0.006816430017352104, -0.008945516310632229, 0.003637888003140688]... (1536 entries)\n"
     ]
    }
   ],
   "source": [
    "example_entry = list(document_embeddings.items())[0]\n",
    "print(f\"{example_entry[0]} : {example_entry[1][:5]}... ({len(example_entry[1])} entries)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9767bdda-af3e-4332-ab73-7995b876ac00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_similarity(x: list, y: list) -> float:\n",
    "    \"\"\"\n",
    "    Returns the similarity between two vectors.\n",
    "    \n",
    "    Because OpenAI Embeddings are normalized to length 1, the cosine similarity is the same as the dot product.\n",
    "    \"\"\"\n",
    "    return np.dot(np.array(x), np.array(y))\n",
    "\n",
    "def order_document_sections_by_query_similarity(query: str, contexts: dict) -> list:\n",
    "    \"\"\"\n",
    "    Find the query embedding for the supplied query, and compare it against all of the pre-calculated document embeddings\n",
    "    to find the most relevant sections. \n",
    "    \n",
    "    Return the list of document sections, sorted by relevance in descending order.\n",
    "    \"\"\"\n",
    "    query_embedding = get_embedding(query)\n",
    "    \n",
    "    document_similarities = sorted([\n",
    "        (vector_similarity(query_embedding, doc_embedding), doc_index) for doc_index, doc_embedding in contexts.items()\n",
    "    ], reverse=True)\n",
    "    \n",
    "    return document_similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "37383d84-9cef-4fab-9f88-663aa05d7382",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8160402677862534,\n",
       "  ('mlops-intelligent-products-essentials_6.txt',\n",
       "   'ML engineersIntelligent Products Essentials helps ML engineers to automate the operation of ML models in a timely and reliable fashion. ML engineers manage the CI/CD pipelines that support the deployment of the ML pipeline, model, and in some cases, the prediction service.The following diagram shows the MLOps architecture of Intelligent Products Essentials from the perspective of ML engineers.')),\n",
       " (0.8119177672136959,\n",
       "  ('MLOps Continuous delivery and automation pipelines in machine learning_2.txt',\n",
       "   \"DevOps versus MLOpsDevOps is a popular practice in developing and operating large-scale software systems. This practice provides benefits such as shortening the development cycles, increasing deployment velocity, and dependable releases. To achieve these benefits, you introduce two concepts in the software system development:Continuous Integration (CI)Continuous Delivery (CD)An ML system is a software system, so similar practices apply to help guarantee that you can reliably build and operate ML systems at scale.However, ML systems differ from other software systems in the following ways:Team skills: In an ML project, the team usually includes data scientists or ML researchers, who focus on exploratory data analysis, model development, and experimentation. These members might not be experienced software engineers who can build production-class services.Development: ML is experimental in nature. You should try different features, algorithms, modeling techniques, and parameter configurations to find what works best for the problem as quickly as possible. The challenge is tracking what worked and what didn't, and maintaining reproducibility while maximizing code reusability.Testing: Testing an ML system is more involved than testing other software systems. In addition to typical unit and integration tests, you need data validation, trained model quality evaluation, and model validation.\")),\n",
       " (0.8114114906775289,\n",
       "  ('Delivering on the Vision of MLOps_20.txt',\n",
       "   ' Level 3 At this level, organizations are delivering ML in an efficient, effective manner, have seen the benefits produced, and have grown to multiple data scientists. They have a program synergistic with MLOps and can start to look at how they optimize their efforts. AI developers are working closely with software developers in a workflow that is consistent across the MLOps and DevOps flows and processes.  ')),\n",
       " (0.8109099755194479,\n",
       "  ('Delivering on the Vision of MLOps_2.txt',\n",
       "   'Summary This report is targeted at Business and IT decision-makers as they look to implement MLOps, which is an approach to deliver Machine Learning- (ML-) based innovation projects. As well as describing how to address the impact of ML across the development cycle, it presents an approach based on maturity levels such that the organization can build on existing progress.The paper is for practitioners who require practical advice on MLOps, rather than general principles of ML. It references ML-related activities and their importance but does not go into technical detail about the specifics of ML nor associated activities.While the paper uses Azure Machine Learning and its documentation as a reference point, its guidance will apply to any ML environment.Drivers to MLOps Over the decades, data has proven to be a competitive differentiator. Once it was exclusively reports built by IT from overnight-batch-loaded data warehouses, but top performers have moved from passive reporting to predictive and prescriptive analytics, growing their skills in data science, and changing accepted paradigms as they derive insights to drive their businesses forward.In recent years, rapidly falling costs of processing and increased throughput have unlocked new opportunities for organizations to maximize their data assets. Many companies have spent years or even decades collecting data in their data warehouses, data marts, data lakes, operational hubs, etc., and some now have the infrastructure and tools to act on the data optimally.Based on established scientific principles, machine learning (ML) can deliver even greater levels of insight from data than traditional approaches, straight to the point of need, and without manual intervention. As shown in Figure 1, ML unlocks a broad range of opportunities across vertical sectors: the rewards will be greatest for those who have the skills, experience, and capabilities they need to deliver on its potential. ')),\n",
       " (0.8106132113394071,\n",
       "  ('Delivering on the Vision of MLOps_17.txt',\n",
       "   ' Level 2 Manager organizations are actively looking to deliver the benefits of ML and have made some discrete progress but now need to consolidate and co-ordinate so their efforts can scale. MLOps allows your efforts to scale. “There is no better place to apply Azure Machine Learning’s MLOps than Office products due to the very large scale (hundreds of millions of users daily) of the product. MLOps was intended for this level of big data,” said Anand from Microsoft Office, whose story can be found below. Organizations at this level may be coordinating development and ML activities but are inefficient and struggle to deliver value in a measurable way. The opportunity exists to start  to drive MLOps as a practice, assuring a framework of governance and tooling that can minimize bottlenecks as efforts progress.'))]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_document_sections_by_query_similarity(\"Benefits of Ml\", document_embeddings)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b394f791-bcb1-4ba7-a70a-f42866cfc480",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.8944063934338102,\n",
       "  ('Delivering on the Vision of MLOps_3.txt',\n",
       "   ' Use Cases are Becoming Vast for ML Pioneers Across a Wide Variety of Areas These are still early days for ML, and success is not a given. Adoption faces several challenges: •  Senior management does not always see ML as strategic, and it can be difficult to measure and manage the value of ML projects. •  ML initiatives can work in isolation from each other, resulting in difficulties aligning workflows between ML and other teams. •  To be effective, ML training requires large quantities of high-quality data, which creates significant overheads across data access, preparation, and ongoing management. •  ML/data science work requires a large amount of trial and error, making it hard to plan  the time required to complete a project. In response, ML adoption requires a cultural shift and a technology environment with people, processes, and platforms operating in the responsive, agile way organizations are looking to operate today: an approach we can call MLOps. Creating such a culture and environment cannot happen overnight: it comes by learning from those at the vanguard of ML how to map the potential of MLOps- driven innovation against an organization’s specific needs and resources.  ')),\n",
       " (0.856700387778393,\n",
       "  ('Delivering on the Vision of MLOps_15.txt',\n",
       "   ' Level 1 These organizations tend to be good at traditional data capture and analytics and may have a level of commitment to cloud-based approaches; for example, they may already be accessing data from the cloud. However, they are yet to engage with ML in a strategic way.   There will be only pockets of data science skills on the team and limited experience of what benefits ML can bring. The main challenge for this level is to know how to kick off ML activities meaningfully, based on existing understanding of DevOps and what it can bring to the table. The priority at this stage is to start building skills and expertise, together with sufficient buy- in at the right level. We would recommend the following actions: •  Focus on developing an architectural understanding, in terms of the kinds of common architectures that may be applicable. •  Get in shape for operational aspects by bringing in collaborative and agile practice across both development and ML activities. •  Identify and set out key success measures, as part of ML strategy.  ')),\n",
       " (0.8565846981945116,\n",
       "  ('MLOps Continuous delivery and automation pipelines in machine learning_7.txt',\n",
       "   \" Challenges MLOps level 0 is common in many businesses that are beginning to apply ML to their use cases. This manual, data-scientist-driven process might be sufficient when models are rarely changed or trained. In practice, models often break when they are deployed in the real world. The models fail to adapt to changes in the dynamics of the environment, or changes in the data that describes the environment. For more information,see Why Machine Learning Models Crash and Burn in Production.To address these challenges and to maintain your model's accuracy in production, you need to do the following:Actively monitor the quality of your model in production: Monitoring lets you detect performance degradation and model staleness. It acts as a cue to a new experimentation iteration and (manual) retraining of the model on new data.Frequently retrain your production models: To capture the evolving and emerging patterns, you need to retrain your model with the most recent data. For example, if your app recommends fashion products using ML, its recommendations should adapt to the latest trends and products.Continuously experiment with new implementations to produce the model: To harness the latest ideas and advances in technology, you need to try out new implementations such as feature engineering, model architecture, and hyperparameters. For example, if you use computer vision in face detection, face patterns are fixed, but better new techniques can improve the detection accuracy.To address the challenges of this manual process, MLOps practices for CI/CD and CT are helpful. By deploying an ML training pipeline, you can enable CT, and you can set up a CI/CD system to rapidly test, build, and deploy new implementations of the ML pipeline. These features are discussed in more detail in the next sections.\")),\n",
       " (0.8558650224358404,\n",
       "  ('ML-Engineering-Ebook-Final_5.txt',\n",
       "   'Machine Learning Engineering for the Real World 8Despite many companies going all in on ML, hiring massive teams of highly compensated data scientists and devoting huge amounts of financial and temporal resources, these Hubris: 5%Cost: 10% projects end up failing at incredibly high rates. This eBook covers the six major causes of project failure and why they result in so many projects failing, being abandoned or taking longer than necessary to reach production. In each section, we will show the solutions to Planning: 30% these common problems and explain the processes involved in reaching those solutions Fragility: 15%so you can significantly lower the chances of your project getting derailed.These issues are not the result of malicious intent. Rather, they are due in large part to the fact that most ML projects are incredibly challenging and complex, and are composed of algorithmic software tooling that is hard to explain to a layperson (hence the breakdowns Technology: 15%in communication with business units that most projects endure). With such complex solutions in play, so many moving parts and a world of corporations trying to win in this new data-focused arms race and profit from ML as quickly as possible, it’s no wonder that the perilous journey of taking a solution to a point of stability in production fails so frequently. Scoping: 25%This book is meant to show how these elements pose a risk to projects and to teach the tools that help minimize the risk of each. By focusing on each of these areas in a  Primary reasons for ML project failures. Figure 1.2 shows some rough estimates of the primary  conscientious and deliberate manner, many of these risks can be significantly mitigated, if reasons why projects fail. Most commonly, data science teams are either inexperienced with using  not eliminated entirely. a large-scale production-grade model to solve a particular need or simply fail to understand what the desired outcome from the business is. ')),\n",
       " (0.8540651512268362,\n",
       "  ('Delivering on the Vision of MLOps_23.txt',\n",
       "   '  Level 4 should see an organization having scaled up ML efforts following a consistent approach, therefore in a position to broaden experimentation and use different techniques. Organizations will be able to assess performance and behavior, looking at questions such as data drift to further enhance and optimize ML-based applications.   Conclusion: Proactively Adopt MLOps As seen, MLOps is an essential discipline for a winning organization – one that intends to retain relevancy through the next decade, through faster time to market, and trustworthy and ethical AI using platforms such as Azure for Machine Learning. The following summary recommendations can support the creation of an action plan, wherever an organization is in  maturity terms: Be prepared for ML-driven change. As Sze-Wan Ng Director, Analytics & Development at TransLink said, “The organization must have a willingness to try new things.” TransLink took risks with ML and it paid off. No plateau is comfortable for long, and organizational competitiveness of the future will be defined by ML and MLOps. ML-driven success will not  come to organizations that keep the status quo. Align the ML roadmap with business priorities. Budgets seldom arise specifically for improving maturity. The skilled enterprise technology leader manages potentially conflicting goals, delivering both business wins and improved maturity. The MLOps leader is in a prime position to not only deliver business wins but also create the projects that utilize machine learning. Infusing ML into the enterprise’s endeavors is as important as creating new projects  for ML. Focus on onboarding. Particularly lower-level organizations can recognize data as a discipline, not an afterthought. When new data science team members are brought into the organization, they can be brought up to speed in weeks, not quarters, based on documentation, adherence to reasonable, common constructs in the data environment, and  defined business goals. Embrace transparency and predictability. For MLOps success, incorporate governance and security frameworks from the outset. For example, though they may not have perfected it yet, ML Operators take measures to eliminate model bias and the potential for malicious use of ML. They understand the importance of re-running experiments to replicate results and  have overcome difficulties in selecting the correct ML algorithms. Overall, organizations can target fast-track movement toward active adoption of MLOps, incorporating all of the elements stated above and with an eye on the next level, within the next one to three years. Enterprises that remain at a lower level will find themselves at a significant disadvantage compared to those in a position to scale their ML efforts to deliver real business advantage. '))]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_document_sections_by_query_similarity(\"challenges of ML adoption\", document_embeddings)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfb42fef-3b04-45f9-8302-d431ddbd00cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Context separator contains 3 tokens'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SECTION_LEN = 500\n",
    "SEPARATOR = \"\\n* \"\n",
    "ENCODING = \"cl100k_base\"  # encoding for text-embedding-ada-002\n",
    "\n",
    "encoding = tiktoken.get_encoding(ENCODING)\n",
    "separator_len = len(encoding.encode(SEPARATOR))\n",
    "\n",
    "f\"Context separator contains {separator_len} tokens\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20a619ca-256f-4292-b6a2-e4fe5f0fda55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_prompt(question: str, context_embeddings: dict, df: pd.DataFrame) -> str:\n",
    "    \"\"\"\n",
    "    Fetch relevant \n",
    "    \"\"\"\n",
    "    most_relevant_document_sections = order_document_sections_by_query_similarity(question, context_embeddings)\n",
    "    \n",
    "    chosen_sections = []\n",
    "    chosen_sections_len = 0\n",
    "    chosen_sections_indexes = []\n",
    "     \n",
    "    for _, section_index in most_relevant_document_sections:\n",
    "        # Add contexts until we run out of space.        \n",
    "        document_section = df.loc[section_index]\n",
    "        \n",
    "        chosen_sections_len += document_section.tokens + separator_len\n",
    "        if chosen_sections_len > MAX_SECTION_LEN:\n",
    "            break\n",
    "            \n",
    "        chosen_sections.append(SEPARATOR + document_section.content.replace(\"\\n\", \" \"))\n",
    "        chosen_sections_indexes.append(str(section_index))\n",
    "            \n",
    "    # Useful diagnostic information\n",
    "    print(f\"Selected {len(chosen_sections)} document sections:\")\n",
    "    print(\"\\n\".join(chosen_sections_indexes))\n",
    "    \n",
    "    header = \"\"\"Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\\n\\nContext:\\n\"\"\"\n",
    "    \n",
    "    return header + \"\".join(chosen_sections) + \"\\n\\n Q: \" + question + \"\\n A:\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8ec992a9-5538-4cd4-b954-e1c7be104e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 1 document sections:\n",
      "('mlops-intelligent-products-essentials_2.txt', \"MLOpsAs described in Hidden technical debt in ML systems, the ML code is only a small part of mature ML systems. In addition to the ML code and high-quality data, you need a way to put your ML processes into operation.MLOps is a practice which helps companies to build, deploy and put your ML system into operation in a rapid, repeatable, and reliable manner. MLOps is an application of DevOps principles to ML systems. MLOps is an engineering culture and practice that's intended to unify ML system development (Dev) and ML system operation (Ops). The objective of MLOps is to provide a set of standardized processes and technology capabilities for building, deploying, and putting ML systems into operation rapidly and reliably.The following sections discuss how MLOps can be implemented with Intelligent Products Essentials and Vertex AI.MLOps personasThe preceding diagram shows the following component and core MLOps user personas:Intelligent Products Essentials: stores customer data, device data, device telemetry, and ownership data across BigQuery and Cloud Storage.Data scientists: responsible for analyzing data stored in Intelligent Products Essentials , feature engineering, model development, model evaluation, and building a ML pipeline.ML engineers: responsible for orchestrating and hosting model deployment at scale.The following sections describe the MLOps architecture from the perspective of data scientists and ML engineers.\")\n",
      "===\n",
      " Answer the question as truthfully as possible using the provided context, and if the answer is not contained within the text below, say \"I don't know.\"\n",
      "\n",
      "Context:\n",
      "\n",
      "* MLOpsAs described in Hidden technical debt in ML systems , the ML code is only a small part of mature ML systems . In addition to the ML code and high-quality data , you need a way to put your ML processes into operation.MLOps is a practice which helps companies to build , deploy and put your ML system into operation in a rapid , repeatable , and reliable manner . MLOps is an application of DevOps principles to ML systems . MLOps is an engineering culture and practice that 's intended to unify ML system development ( Dev ) and ML system operation ( Ops ) . The objective of MLOps is to provide a set of standardized processes and technology capabilities for building , deploying , and putting ML systems into operation rapidly and reliably.The following sections discuss how MLOps can be implemented with Intelligent Products Essentials and Vertex AI.MLOps personasThe preceding diagram shows the following component and core MLOps user personas : Intelligent Products Essentials : stores customer data , device data , device telemetry , and ownership data across BigQuery and Cloud Storage.Data scientists : responsible for analyzing data stored in Intelligent Products Essentials , feature engineering , model development , model evaluation , and building a ML pipeline.ML engineers : responsible for orchestrating and hosting model deployment at scale.The following sections describe the MLOps architecture from the perspective of data scientists and ML engineers .\n",
      "\n",
      " Q: What are MLOps Drivers\n",
      " A:\n"
     ]
    }
   ],
   "source": [
    "prompt = construct_prompt(\n",
    "    \"What are MLOps Drivers\",\n",
    "    document_embeddings,\n",
    "    data\n",
    ")\n",
    "\n",
    "print(\"===\\n\", prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ae6a4e4d-b51e-49a5-a04e-62683d817cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "COMPLETIONS_API_PARAMS = {\n",
    "    # We use temperature of 0.0 because it gives the most predictable, factual answer.\n",
    "    \"temperature\": 0.0,\n",
    "    \"max_tokens\": 300,\n",
    "    \"model\": COMPLETIONS_MODEL,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f5061e66-8e77-413b-b979-9b12857778b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer_query_with_context(\n",
    "    query: str,\n",
    "    df: pd.DataFrame,\n",
    "    document_embeddings: dict,\n",
    "    show_prompt: bool = False\n",
    ") -> str:\n",
    "    prompt = construct_prompt(\n",
    "        query,\n",
    "        document_embeddings,\n",
    "        df\n",
    "    )\n",
    "    \n",
    "    if show_prompt:\n",
    "        print(prompt)\n",
    "\n",
    "    response = openai.Completion.create(\n",
    "                prompt=prompt,\n",
    "                **COMPLETIONS_API_PARAMS\n",
    "            )\n",
    "\n",
    "    return response[\"choices\"][0][\"text\"].strip(\" \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8e8d1c78-793c-4219-9d16-bdfada8a8715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 1 document sections:\n",
      "('Delivering on the Vision of MLOps_2.txt', 'Summary This report is targeted at Business and IT decision-makers as they look to implement MLOps, which is an approach to deliver Machine Learning- (ML-) based innovation projects. As well as describing how to address the impact of ML across the development cycle, it presents an approach based on maturity levels such that the organization can build on existing progress.The paper is for practitioners who require practical advice on MLOps, rather than general principles of ML. It references ML-related activities and their importance but does not go into technical detail about the specifics of ML nor associated activities.While the paper uses Azure Machine Learning and its documentation as a reference point, its guidance will apply to any ML environment.Drivers to MLOps Over the decades, data has proven to be a competitive differentiator. Once it was exclusively reports built by IT from overnight-batch-loaded data warehouses, but top performers have moved from passive reporting to predictive and prescriptive analytics, growing their skills in data science, and changing accepted paradigms as they derive insights to drive their businesses forward.In recent years, rapidly falling costs of processing and increased throughput have unlocked new opportunities for organizations to maximize their data assets. Many companies have spent years or even decades collecting data in their data warehouses, data marts, data lakes, operational hubs, etc., and some now have the infrastructure and tools to act on the data optimally.Based on established scientific principles, machine learning (ML) can deliver even greater levels of insight from data than traditional approaches, straight to the point of need, and without manual intervention. As shown in Figure 1, ML unlocks a broad range of opportunities across vertical sectors: the rewards will be greatest for those who have the skills, experience, and capabilities they need to deliver on its potential. ')\n",
      "\n",
      "Q: can you provide multiple approaches to implement mlops\n",
      "A: Yes, the report presents an approach based on maturity levels such that the organization can build on existing progress. Additionally, the report references ML-related activities and their importance and uses Azure Machine Learning and its documentation as a reference point.\n"
     ]
    }
   ],
   "source": [
    "query = \"can you provide multiple approaches to implement mlops\"\n",
    "answer = answer_query_with_context(query, data, document_embeddings)\n",
    "\n",
    "print(f\"\\nQ: {query}\\nA: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "71ed63f1-367b-4329-a824-babf28b12f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "('Delivering on the Vision of MLOps_3.txt', ' Use Cases are Becoming Vast for ML Pioneers Across a Wide Variety of Areas These are still early days for ML, and success is not a given. Adoption faces several challenges: •  Senior management does not always see ML as strategic, and it can be difficult to measure and manage the value of ML projects. •  ML initiatives can work in isolation from each other, resulting in difficulties aligning workflows between ML and other teams. •  To be effective, ML training requires large quantities of high-quality data, which creates significant overheads across data access, preparation, and ongoing management. •  ML/data science work requires a large amount of trial and error, making it hard to plan  the time required to complete a project. In response, ML adoption requires a cultural shift and a technology environment with people, processes, and platforms operating in the responsive, agile way organizations are looking to operate today: an approach we can call MLOps. Creating such a culture and environment cannot happen overnight: it comes by learning from those at the vanguard of ML how to map the potential of MLOps- driven innovation against an organization’s specific needs and resources.  ')\n",
      "('Google_User_1.txt', 'MLOpsIntroductionMachine learning, and by extension a lot of artificial  INTRODUCTIONintelligence, has grown from a niche idea to a tool KEY TERMSthat is being applied in multiple areas and industries.WHAT IS MLOPS?PRINCIPLESAt EE we have been involved in developing and deploying machine learning for a number of appli-cations, including to:PRACTICES•  Assess cyber-risk•  Evaluate financial risk EXPLORE•  Improve search and recommendations in retail web sites•  Price used vehicles PITFALLS•  Improve logistics and supply chainsAn ML solution depends on both the algorithm - which is code - and the data used to develop and train that algorithm.  For this reason, developing and operating solutions that use ML components is different to standard software development. ')\n",
      "\n",
      "Q: Give me examples of ML use cases\n",
      "A: Examples of ML use cases include assessing cyber-risk, evaluating financial risk, improving search and recommendations in retail web sites, pricing used vehicles, and improving logistics and supply chains.\n"
     ]
    }
   ],
   "source": [
    "query = \"Give me examples of ML use cases\"\n",
    "answer = answer_query_with_context(query, data, document_embeddings)\n",
    "\n",
    "print(f\"\\nQ: {query}\\nA: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4a343870-1571-4e0b-a5b0-ff048a3839c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "('Delivering on the Vision of MLOps_29.txt', '  Because data science teams now have the ability to process the data, Johnson Controls now has up to 70 different types of sensors on their chillers with more coming online.  Overall results are that both unplanned downtime and mean time to repair are down by two-thirds. Chiller shutdowns, a highly detrimental event for JCI, has been drastically reduced. They predict potential shutdowns several days before and can comfortably intervene to keep customers happy and save money and time. “Using the MLOps capabilities in Azure Machine Learning, we were able to increase productivity and enhance operations, going to production in a timely fashion and creating a repeatable process,” says Chennupati.')\n",
      "('Delivering on the Vision of MLOps_27.txt', ' Company Background  Microsoft (Nasdaq “MSFT” @microsoft) enables digital transformation for the era of an intelligent cloud and an intelligent edge. Its mission is to empower every person and every organization  on the planet to achieve more. Additional materials and examples of Microsoft’s Azure Machine Learning, and MLOps, are available as follows: •  Free trial: https://azure.microsoft.com/en-us/free/services/machine-learning/ •  Website: https://azure.microsoft.com/en-us/services/machine-learning/mlops/ •  GitHub: https://github.com/Microsoft/MLOps •  Documentation: https://docs.microsoft.com/en-us/azure/machine-learning/service/concept-model- management-and-deployment   Johnson Controls   Company Background For over 130 years, Johnson Controls has produced fire, HVAC, and security equipment for buildings. The company, with its broad array of product lines, is at the forefront of the smart city  revolution, with data science and machine learning (ML) as key elements of their approach. As part of its focus on digital transformation, Johnson Controls formed a data science team four years ago and now employs over 50 people involved in ML projects. The vision is to scale use of ML from small equipment and sensors to entire buildings. The company is currently involved  in what will be the smartest building in the world, in Dubai.  Opportunity To deliver on its vision, Johnson Controls needed to keep pace with the demand for its building equipment without scaling the cost. Chillers, in particular, are key to building efficiency. Johnson Controls runs over 4,000 chillers, streaming time-series data volumes up to several terabytes. The opportunity to improve both efficiency and function through real-time data  analysis was abundantly clear. Engineering teams had begun to gain insights from the chiller sensor reads but recognized the need to build fully predictive models. The company knew it needed to turn to the cloud and machine learning for new, improved insights that would deliver both cost savings and better  business decision making. ')\n",
      "\n",
      "Q: Johnson Controls has how many sensors on their chillers\n",
      "A: Johnson Controls has up to 70 different types of sensors on their chillers.\n"
     ]
    }
   ],
   "source": [
    "query = \"Johnson Controls has how many sensors on their chillers\"\n",
    "answer = answer_query_with_context(query, data, document_embeddings)\n",
    "\n",
    "print(f\"\\nQ: {query}\\nA: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3839bfde-4bdb-4201-8905-095910c82b21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 2 document sections:\n",
      "('Google_User_15.txt', 'Ways of deploying your modelMicroservices: API-ify your model (Pickle, Joblib) Shared service: host your model in a dedicated tool, possibly automatedDeploy model together with your application  Streaming: load your model in memory (PMML, ONNX)(Python, MLlib)Deploy model as SQL stored procedureMany cloud providers and ML tools provide solutions for model deployment that integrate closely with their machine learning and data environments. These can greatly speed up deployment and ease infrastructure overhead such as:•  GCP Vertex AI•  AWS Sagemaker•  MLFlow')\n",
      "('MLOps Continuous delivery and automation pipelines in machine learning_3.txt', \"Deployment: In ML systems, deployment isn't as simple as deploying an offline-trained ML model as a prediction service. ML systems can require you to deploy a multi-step pipeline to automatically retrain and deploy model. This pipeline adds complexity and requires you to automate steps that are manually done before deployment by data scientists to train and validate new models.Production: ML models can have reduced performance not only due to suboptimal coding, but also due to constantly evolving data profiles. In other words, models can decay in more ways than conventional software systems, and you need to consider this degradation. Therefore, you need to track summary statistics of your data and monitor the online performance of your model to send notifications or roll back when values deviate from your expectations.ML and other software systems are similar in continuous integration of source control, unit testing, integration testing, and continuous delivery of the software module or the package. However, in ML, there are a few notable differences:CI is no longer only about testing and validating code and components, but also testing and validating data, data schemas, and models.CD is no longer about a single software package or a service, but a system (an ML training pipeline) that should automatically deploy another service (model prediction service).CT is a new property, unique to ML systems, that's concerned with automatically retraining and serving the models.The following section discusses the typical steps for training and evaluating an ML model to serve as a prediction service.\")\n",
      "\n",
      "Q: how should I deploy ML models\n",
      "A: Many cloud providers and ML tools provide solutions for model deployment that integrate closely with their machine learning and data environments. These can greatly speed up deployment and ease infrastructure overhead. Examples include GCP Vertex AI, AWS Sagemaker, and MLFlow. Additionally, deployment of ML models is not as simple as deploying an offline-trained ML model as a prediction service. ML systems can require you to deploy a multi-step pipeline to automatically retrain and deploy model. This pipeline adds complexity and requires you to automate steps that are manually done before deployment by data scientists to train and validate new models.\n"
     ]
    }
   ],
   "source": [
    "query = \"how should I deploy ML models\"\n",
    "answer = answer_query_with_context(query, data, document_embeddings)\n",
    "\n",
    "print(f\"\\nQ: {query}\\nA: {answer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6143a8c-e4f7-4ed0-b3c6-4167048a1a44",
   "metadata": {},
   "source": [
    "#### To store the embeddings txt format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "2f4b6c64-7886-484c-9b27-e16d7ea20b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a bucket.\n",
    "#bucket = storage_client.bucket('mlops_documents')\n",
    "\n",
    "# Write the dictionary to a file.\n",
    "#with open('embedding.txt', 'w') as f:\n",
    "    #f.write(str(document_embeddings))\n",
    "\n",
    "# Upload the file to the bucket.\n",
    "#blob = bucket.blob('embedding.txt')\n",
    "#blob.upload_from_filename('embedding.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484a8582-0a75-405f-885d-b1980f98fe36",
   "metadata": {},
   "source": [
    "#### To store the embeddings csv format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b19605e9-6505-48ef-91db-fd2170baa4cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a gcloud storage client\n",
    "#from google.cloud import storage\n",
    "#import csv\n",
    "\n",
    "#client = storage.Client()\n",
    "\n",
    "# Create a gcloud bucket\n",
    "#bucket = client.get_bucket('mlops_documents')\n",
    "\n",
    "# Create a file in the bucket\n",
    "#blob = bucket.blob('my_dict.csv')\n",
    "\n",
    "# Create the csv file\n",
    "#with open('my_dict.csv', 'w', newline='') as csvfile:\n",
    "    # Create a csv writer\n",
    "    #writer = csv.DictWriter(csvfile, fieldnames=document_embeddings.keys())\n",
    "\n",
    "    # Write the csv file\n",
    "    #writer.writeheader()\n",
    "    #writer.writerow(document_embeddings)\n",
    "\n",
    "# Upload csv file to the bucket\n",
    "#blob.upload_from_filename('my_dict.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea177a68-8880-4a52-8afa-cdb731f5d15d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python38",
   "name": "common-cpu.m103",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m103"
  },
  "kernelspec": {
   "display_name": "python38",
   "language": "python",
   "name": "python38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
